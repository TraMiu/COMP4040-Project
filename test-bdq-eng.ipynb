{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:48:31.809693Z","iopub.status.busy":"2024-06-05T08:48:31.809376Z","iopub.status.idle":"2024-06-05T08:48:31.814079Z","shell.execute_reply":"2024-06-05T08:48:31.813113Z","shell.execute_reply.started":"2024-06-05T08:48:31.809670Z"},"id":"TnhanWBXCSnE","trusted":true},"outputs":[],"source":["import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["### Wandb session"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import wandb\n","wandb.login(key='')\n","wandb.init(project='huggingface')"]},{"cell_type":"markdown","metadata":{},"source":["# Customing marian\n","Description of the model format a.b.c\n","* **a** means the phase of the dataset. Phase 1 means the first 1000 high-quality English-Bahnar sentences\n","* **b** means the direction of translation. Direction 1 means Bahnar to English\n","* **c** means the special technique and version to develop this model.\n","\n","Technique 0 means just feed English-Bahnar data into the pretrained model. Technique 1 means feed both English-Bahnar and English-Vietnamese into the model\n"]},{"cell_type":"markdown","metadata":{},"source":["### Installing dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:48:31.857518Z","iopub.status.busy":"2024-06-05T08:48:31.857272Z","iopub.status.idle":"2024-06-05T08:49:11.738176Z","shell.execute_reply":"2024-06-05T08:49:11.736929Z","shell.execute_reply.started":"2024-06-05T08:48:31.857498Z"},"trusted":true},"outputs":[],"source":["# !pip install -q -U sentencepiece\n","# !pip install -q -U datasets\n","# !pip install -q -U sacrebleu"]},{"cell_type":"markdown","metadata":{},"source":["### Importing libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:11.741484Z","iopub.status.busy":"2024-06-05T08:49:11.740608Z","iopub.status.idle":"2024-06-05T08:49:28.888226Z","shell.execute_reply":"2024-06-05T08:49:28.887403Z","shell.execute_reply.started":"2024-06-05T08:49:11.741445Z"},"id":"I4SpTMyU2wcv","trusted":true},"outputs":[],"source":["import torch\n","import sentencepiece\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainer, Seq2SeqTrainingArguments\n","from transformers import DataCollatorForSeq2Seq, EarlyStoppingCallback\n","from datasets import load_dataset, load_metric\n","from customing_marian import MarianMTModel\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from datasets import Dataset, concatenate_datasets\n","\n","import sacrebleu"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:28.890184Z","iopub.status.busy":"2024-06-05T08:49:28.889473Z","iopub.status.idle":"2024-06-05T08:49:28.894857Z","shell.execute_reply":"2024-06-05T08:49:28.893805Z","shell.execute_reply.started":"2024-06-05T08:49:28.890149Z"},"trusted":true},"outputs":[],"source":["from datasets import Dataset, concatenate_datasets"]},{"cell_type":"markdown","metadata":{},"source":["### Reproducibility"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:28.897782Z","iopub.status.busy":"2024-06-05T08:49:28.897444Z","iopub.status.idle":"2024-06-05T08:49:28.993962Z","shell.execute_reply":"2024-06-05T08:49:28.992976Z","shell.execute_reply.started":"2024-06-05T08:49:28.897748Z"},"id":"UjL5cNEc2wcw","trusted":true},"outputs":[],"source":["RANDOM_SEED = 42\n","\n","torch.manual_seed(RANDOM_SEED)\n","# If you are using CUDA\n","torch.cuda.manual_seed_all(RANDOM_SEED)\n","# Check if GPU is available\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","PADDING_LEN = 228\n","IS_CUSTOMED = False"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the pretrained model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:28.995720Z","iopub.status.busy":"2024-06-05T08:49:28.995349Z","iopub.status.idle":"2024-06-05T08:49:39.782615Z","shell.execute_reply":"2024-06-05T08:49:39.781601Z","shell.execute_reply.started":"2024-06-05T08:49:28.995685Z"},"id":"cR6SJn0l2wcx","trusted":true},"outputs":[],"source":["model_name = \"opus-mt-en-vi\"  # Example model for Bahnar to English\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = MarianMTModel.from_pretrained(model_name).to(device)"]},{"cell_type":"markdown","metadata":{},"source":["### Loading the dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:39.784232Z","iopub.status.busy":"2024-06-05T08:49:39.783942Z","iopub.status.idle":"2024-06-05T08:49:40.066193Z","shell.execute_reply":"2024-06-05T08:49:40.065152Z","shell.execute_reply.started":"2024-06-05T08:49:39.784208Z"},"id":"LJz0myyQ2wcy","trusted":true},"outputs":[],"source":["with open('data/KJV-Bible-ba-en/bdq-eng.train.bdq', 'r', encoding='utf-8') as file_ba:\n","    ba_data = file_ba.readlines()\n","with open('data/KJV-Bible-ba-en/bdq-eng.train.eng', 'r', encoding='utf-8') as file_en:\n","    en_data = file_en.readlines()\n","assert len(ba_data) == len(en_data), \"The files don't have the same number of lines.\"\n","train_df = pd.DataFrame({'English': en_data, 'Bahnar': ba_data})\n","train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=RANDOM_SEED)\n","\n","ba_en_train_dataset = Dataset.from_pandas(train_df)\n","ba_en_val_dataset = Dataset.from_pandas(val_df)\n","\n","with open('data/PhoMT-vi-en/dev.vi', 'r', encoding='utf-8') as file_vi:\n","    vi_data = file_vi.readlines()\n","with open('data/PhoMT-vi-en/dev.en', 'r', encoding='utf-8') as file_en:\n","    en_data = file_en.readlines()\n","assert len(vi_data) == len(en_data), \"The files don't have the same number of lines.\"\n","train_df = pd.DataFrame({'English': en_data, 'Vietnamese': vi_data})\n","\n","vi_en_train_dataset = Dataset.from_pandas(train_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:40.068241Z","iopub.status.busy":"2024-06-05T08:49:40.067951Z","iopub.status.idle":"2024-06-05T08:49:40.102088Z","shell.execute_reply":"2024-06-05T08:49:40.101226Z","shell.execute_reply.started":"2024-06-05T08:49:40.068217Z"},"trusted":true},"outputs":[],"source":["\n","with open('data/Doccano-ba-en/bdq-eng.test.bdq', 'r', encoding='utf-8') as file_ba:\n","    ba_data = file_ba.readlines()\n","with open('data/Doccano-ba-en/bdq-eng.test.eng', 'r', encoding='utf-8') as file_en:\n","    en_data = file_en.readlines()\n","assert len(ba_data) == len(en_data), \"The files don't have the same number of lines.\"\n","test_df = pd.DataFrame({'English': en_data, 'Bahnar': ba_data})\n","ba_en_test_dataset = Dataset.from_pandas(test_df)\n","\n","print(len(ba_en_train_dataset), len(ba_en_val_dataset), len(ba_en_test_dataset))\n","print(len(vi_en_train_dataset))"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocess the dataset with tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:40.103797Z","iopub.status.busy":"2024-06-05T08:49:40.103370Z","iopub.status.idle":"2024-06-05T08:49:47.503435Z","shell.execute_reply":"2024-06-05T08:49:47.502574Z","shell.execute_reply.started":"2024-06-05T08:49:40.103767Z"},"trusted":true},"outputs":[],"source":["def preprocess_function_source(examples):\n","    inputs = examples['Vietnamese']\n","    targets = examples['English']\n","    labels = tokenizer(targets, max_length=PADDING_LEN, padding='max_length', truncation=True)\n","\n","    # Set up the tokenizer for Vietnamese\n","    with tokenizer.as_target_tokenizer():\n","        model_inputs = tokenizer(inputs, max_length=PADDING_LEN, padding='max_length', truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_vi_en = vi_en_train_dataset.map(preprocess_function_source, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for example in tokenized_vi_en:\n","    example['is_src'] = IS_CUSTOMED"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:47.504911Z","iopub.status.busy":"2024-06-05T08:49:47.504545Z","iopub.status.idle":"2024-06-05T08:49:59.620481Z","shell.execute_reply":"2024-06-05T08:49:59.619607Z","shell.execute_reply.started":"2024-06-05T08:49:47.504871Z"},"id":"hs7OvOKu2wcz","trusted":true},"outputs":[],"source":["def preprocess_function_target(examples):\n","    inputs = examples['Bahnar']\n","    targets = examples['English']\n","    labels = tokenizer(targets, max_length=PADDING_LEN, padding='max_length', truncation=True)\n","\n","    # Set up the tokenizer for Vietnamese\n","    with tokenizer.as_target_tokenizer():\n","        model_inputs = tokenizer(inputs, max_length=PADDING_LEN, padding='max_length', truncation=True)\n","\n","    model_inputs[\"labels\"] = labels[\"input_ids\"]\n","    return model_inputs\n","\n","tokenized_ba_en = ba_en_train_dataset.map(preprocess_function_target, batched=True)\n","tokenized_ba_en_val = ba_en_val_dataset.map(preprocess_function_target, batched=True)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for example in tokenized_ba_en:\n","    example['is_tgt'] = IS_CUSTOMED\n","for example in tokenized_ba_en_val:\n","    example['is_tgt'] = IS_CUSTOMED"]},{"cell_type":"markdown","metadata":{},"source":["### Concatenate Vietnamese-English and Bahnar-English Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:59.624514Z","iopub.status.busy":"2024-06-05T08:49:59.624223Z","iopub.status.idle":"2024-06-05T08:49:59.635854Z","shell.execute_reply":"2024-06-05T08:49:59.634970Z","shell.execute_reply.started":"2024-06-05T08:49:59.624490Z"},"trusted":true},"outputs":[],"source":["tokenized_viAndba_en = concatenate_datasets([tokenized_vi_en, tokenized_ba_en ])\n","# viOrba_en_dataset is now a combined dataset\n","print(tokenized_viAndba_en)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#shuffled_dataset = tokenized_viAndba_en.shuffle(seed=RANDOM_SEED)"]},{"cell_type":"markdown","metadata":{},"source":["\n","# Train the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T08:49:59.637387Z","iopub.status.busy":"2024-06-05T08:49:59.637035Z","iopub.status.idle":"2024-06-05T09:01:33.503093Z","shell.execute_reply":"2024-06-05T09:01:33.501546Z","shell.execute_reply.started":"2024-06-05T08:49:59.637356Z"},"trusted":true},"outputs":[],"source":["class CustomSeq2SeqTrainer(Seq2SeqTrainer):\n","    def compute_loss(self, model, inputs, return_outputs=False):\n","        # Extract the `is_tgt` flag from inputs or set it to False if not present\n","        is_tgt = inputs.pop('is_tgt', False)\n","        is_src = inputs.pop('is_src', False)\n","\n","        outputs = model(**inputs, is_tgt=is_tgt, is_src=is_src)\n","        loss = outputs.loss\n","        return (loss, outputs) if return_outputs else loss\n","    \n","\n","print((len(tokenized_viAndba_en)))\n","# Use data collator\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# Step 3: Fine-Tuning the Model on Bahnar to English\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./results\",\n","    evaluation_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=32,\n","    per_device_eval_batch_size=32,\n","    num_train_epochs=10,\n","    weight_decay=0.015,  # L2 regularization\n","    save_total_limit=3,\n",")\n","\n","\n","trainer = CustomSeq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_viAndba_en,\n","    eval_dataset=tokenized_ba_en_val,\n","    data_collator=data_collator,\n",")\n","\n","trainer.train()"]},{"cell_type":"markdown","metadata":{},"source":["# Test the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T09:01:37.970593Z","iopub.status.busy":"2024-06-05T09:01:37.970198Z","iopub.status.idle":"2024-06-05T09:01:37.980539Z","shell.execute_reply":"2024-06-05T09:01:37.978806Z","shell.execute_reply.started":"2024-06-05T09:01:37.970563Z"},"trusted":true},"outputs":[],"source":["import torch\n","from tqdm.auto import tqdm\n","\n","def evaluate_model(model, encode_tokenizer, decode_tokenizer, dataset, device):\n","    model.eval()\n","    prt = True\n","\n","    predictions, references = [], []\n","    for example in tqdm(dataset, desc=\"Translating\"):\n","        with encode_tokenizer.as_target_tokenizer():\n","            input_ids = encode_tokenizer.encode(example['Bahnar'], return_tensors='pt').to(device)\n","\n","        output_ids = model.generate(input_ids, is_tgt=IS_CUSTOMED)[0]\n","        pred = decode_tokenizer.decode(output_ids, skip_special_tokens=True)\n","        predictions.append([pred])\n","\n","        references.append([example['English']])\n","\n","    return predictions, references\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T09:01:48.580526Z","iopub.status.busy":"2024-06-05T09:01:48.579747Z","iopub.status.idle":"2024-06-05T09:03:12.034924Z","shell.execute_reply":"2024-06-05T09:03:12.033246Z","shell.execute_reply.started":"2024-06-05T09:01:48.580493Z"},"id":"CNr4jLFB2wc1","trusted":true},"outputs":[],"source":["test_examples = [{'Bahnar': ex['Bahnar'], 'English': ex['English']} for ex in ba_en_test_dataset]\n","predictions, references = evaluate_model(model, tokenizer, tokenizer, test_examples, device)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T09:05:33.648861Z","iopub.status.busy":"2024-06-05T09:05:33.648435Z","iopub.status.idle":"2024-06-05T09:05:33.657345Z","shell.execute_reply":"2024-06-05T09:05:33.656359Z","shell.execute_reply.started":"2024-06-05T09:05:33.648810Z"},"id":"uUnFFH5g2wc6","trusted":true},"outputs":[],"source":["predictions[0], references[0] # Check format of predictions and references"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T09:05:36.811138Z","iopub.status.busy":"2024-06-05T09:05:36.810505Z","iopub.status.idle":"2024-06-05T09:05:36.819053Z","shell.execute_reply":"2024-06-05T09:05:36.817510Z","shell.execute_reply.started":"2024-06-05T09:05:36.811104Z"},"trusted":true},"outputs":[],"source":["len(predictions), len(references)"]},{"cell_type":"markdown","metadata":{},"source":["### Calculate sacreBLEU"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T09:05:41.356115Z","iopub.status.busy":"2024-06-05T09:05:41.355723Z","iopub.status.idle":"2024-06-05T09:05:41.364517Z","shell.execute_reply":"2024-06-05T09:05:41.363570Z","shell.execute_reply.started":"2024-06-05T09:05:41.356082Z"},"trusted":true},"outputs":[],"source":["preds = []\n","refs = []\n","for pred in predictions:\n","    preds.append(pred[0])\n","    \n","for ref in references:\n","    refs.append(ref)\n","\n","print(refs[:2])\n","print(preds[:2])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-05T09:05:44.229027Z","iopub.status.busy":"2024-06-05T09:05:44.228158Z","iopub.status.idle":"2024-06-05T09:05:44.976317Z","shell.execute_reply":"2024-06-05T09:05:44.975164Z","shell.execute_reply.started":"2024-06-05T09:05:44.228995Z"},"trusted":true},"outputs":[],"source":["# Calculate and print the BLEU score\n","bleu = sacrebleu.corpus_bleu(preds, refs)\n","print(\"BLEU: \", round(bleu.score, 2))\n","\n","# Calculate CHRF\n","chrf = sacrebleu.corpus_chrf(preds, refs)\n","print(\"CHRF:\", round(chrf.score, 2))\n","\n","# Calculate TER\n","metric = sacrebleu.metrics.TER()\n","ter = metric.corpus_score(preds, refs)\n","print(\"TER:\", round(ter.score, 2))"]},{"cell_type":"markdown","metadata":{},"source":["### Saving the model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:01:33.516276Z","iopub.status.idle":"2024-06-05T09:01:33.516610Z","shell.execute_reply":"2024-06-05T09:01:33.516457Z","shell.execute_reply.started":"2024-06-05T09:01:33.516444Z"},"trusted":true},"outputs":[],"source":["# Step 5: Save the Model\n","model.save_pretrained(\"./ba-en\")\n","tokenizer.save_pretrained(\"./tokenizer-ba-en\")"]},{"cell_type":"markdown","metadata":{},"source":["### Display translated and references for qualitative evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-06-05T09:01:33.517805Z","iopub.status.idle":"2024-06-05T09:01:33.518275Z","shell.execute_reply":"2024-06-05T09:01:33.518063Z","shell.execute_reply.started":"2024-06-05T09:01:33.518043Z"},"id":"ojla4E232wc9","trusted":true},"outputs":[],"source":["# Display the first 3 prediction-reference pairs\n","for i in range(20):\n","    print(f\"Prediction {i+1}: {predictions[i][0]}\")\n","    print(f\"Reference {i+1}: {references[i][0]}\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","private_outputs":true,"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":5063149,"sourceId":8487291,"sourceType":"datasetVersion"},{"datasetId":5063775,"sourceId":8488207,"sourceType":"datasetVersion"},{"datasetId":5074078,"sourceId":8502007,"sourceType":"datasetVersion"},{"datasetId":5105744,"sourceId":8545653,"sourceType":"datasetVersion"},{"datasetId":5105750,"sourceId":8545660,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
